{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "輕油案子集成學習(針對個別Y).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skywalker0803r/works/blob/master/%E8%BC%95%E6%B2%B9%E6%A1%88%E5%AD%90%E9%9B%86%E6%88%90%E5%AD%B8%E7%BF%92(%E9%87%9D%E5%B0%8D%E5%80%8B%E5%88%A5Y).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJPLhpytI6lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5d4026d-9d96-4c68-d4e9-ee33b179f611"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSFiHb6PJOvn",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi61rOqFI_eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/drive/My Drive/台塑輕油案子/輕油實驗數據(保留大部份欄位,三個基本規則清洗過).csv')\n",
        "train.rename(columns={'N+A in Feed':'NA'},inplace=True)\n",
        "\n",
        "x_columns = ['T10','T50','T90','NA']\n",
        "y_columns = ['C5NP', 'C5IP', 'C5N', 'C6NP',\n",
        "       'C6IP', 'C6N', 'C6A', 'C7NP', 'C7IP', 'C7N', 'C7A', 'C8NP', 'C8IP',\n",
        "       'C8N', 'C8A', 'C9NP', 'C9IP', 'C9N', 'C9A', 'C10NP', 'C10IP', 'C10N',\n",
        "       'C10A']\n",
        "train = train[x_columns+y_columns]\n",
        "X_train = train[x_columns]\n",
        "y_train = train[y_columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGYEmyPYJYso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/台塑輕油案子/test_without_outlier.csv')\n",
        "test.columns = train.columns\n",
        "X_test = test[x_columns]\n",
        "y_test = test[y_columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viiVX5HmJUd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26fcf7c4-7101-4196-ed5c-39326c4f5ae9"
      },
      "source": [
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4521, 4) (170, 4) (4521, 23) (170, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbSD6oggKAhg",
        "colab_type": "text"
      },
      "source": [
        "# 特徵工程"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OGfIgXUJ__v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def 特徵工程(df):\n",
        "  df['T90-T50'] = df['T90']-df['T50']\n",
        "  df['T50-T10'] = df['T50']-df['T10']\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_B9B-XdJIH4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "05988181-4067-4cda-bf1f-2c5bc8c7ed23"
      },
      "source": [
        "train = 特徵工程(train)\n",
        "test = 特徵工程(test)\n",
        "print('加入特徵工程項後目前特徵有:')\n",
        "x_columns = train.drop(y_columns,axis=1).columns.tolist()\n",
        "print(x_columns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "加入特徵工程項後目前特徵有:\n",
            "['T10', 'T50', 'T90', 'NA', 'T90-T50', 'T50-T10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Na20JLqJNGn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "d5c1a869-682a-4360-bc96-0cfb66b77dd4"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T10</th>\n",
              "      <th>T50</th>\n",
              "      <th>T90</th>\n",
              "      <th>NA</th>\n",
              "      <th>C5NP</th>\n",
              "      <th>C5IP</th>\n",
              "      <th>C5N</th>\n",
              "      <th>C6NP</th>\n",
              "      <th>C6IP</th>\n",
              "      <th>C6N</th>\n",
              "      <th>C6A</th>\n",
              "      <th>C7NP</th>\n",
              "      <th>C7IP</th>\n",
              "      <th>C7N</th>\n",
              "      <th>C7A</th>\n",
              "      <th>C8NP</th>\n",
              "      <th>C8IP</th>\n",
              "      <th>C8N</th>\n",
              "      <th>C8A</th>\n",
              "      <th>C9NP</th>\n",
              "      <th>C9IP</th>\n",
              "      <th>C9N</th>\n",
              "      <th>C9A</th>\n",
              "      <th>C10NP</th>\n",
              "      <th>C10IP</th>\n",
              "      <th>C10N</th>\n",
              "      <th>C10A</th>\n",
              "      <th>T90-T50</th>\n",
              "      <th>T50-T10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100.5</td>\n",
              "      <td>119.2</td>\n",
              "      <td>146.5</td>\n",
              "      <td>31.978</td>\n",
              "      <td>0.272</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.059</td>\n",
              "      <td>5.293</td>\n",
              "      <td>2.570</td>\n",
              "      <td>2.819</td>\n",
              "      <td>0.494</td>\n",
              "      <td>10.395</td>\n",
              "      <td>8.070</td>\n",
              "      <td>6.411</td>\n",
              "      <td>2.917</td>\n",
              "      <td>9.138</td>\n",
              "      <td>9.649</td>\n",
              "      <td>4.810</td>\n",
              "      <td>5.373</td>\n",
              "      <td>6.405</td>\n",
              "      <td>9.759</td>\n",
              "      <td>4.590</td>\n",
              "      <td>3.661</td>\n",
              "      <td>0.875</td>\n",
              "      <td>5.257</td>\n",
              "      <td>0.525</td>\n",
              "      <td>0.319</td>\n",
              "      <td>27.3</td>\n",
              "      <td>18.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>99.6</td>\n",
              "      <td>117.9</td>\n",
              "      <td>145.5</td>\n",
              "      <td>31.568</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.062</td>\n",
              "      <td>5.089</td>\n",
              "      <td>2.531</td>\n",
              "      <td>2.804</td>\n",
              "      <td>0.499</td>\n",
              "      <td>10.074</td>\n",
              "      <td>7.958</td>\n",
              "      <td>6.395</td>\n",
              "      <td>2.894</td>\n",
              "      <td>8.970</td>\n",
              "      <td>9.548</td>\n",
              "      <td>4.753</td>\n",
              "      <td>5.443</td>\n",
              "      <td>6.324</td>\n",
              "      <td>9.899</td>\n",
              "      <td>4.301</td>\n",
              "      <td>2.995</td>\n",
              "      <td>0.881</td>\n",
              "      <td>5.591</td>\n",
              "      <td>1.119</td>\n",
              "      <td>0.303</td>\n",
              "      <td>27.6</td>\n",
              "      <td>18.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100.0</td>\n",
              "      <td>118.8</td>\n",
              "      <td>145.6</td>\n",
              "      <td>31.344</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.126</td>\n",
              "      <td>0.061</td>\n",
              "      <td>5.107</td>\n",
              "      <td>2.571</td>\n",
              "      <td>2.771</td>\n",
              "      <td>0.492</td>\n",
              "      <td>10.069</td>\n",
              "      <td>7.913</td>\n",
              "      <td>6.378</td>\n",
              "      <td>2.890</td>\n",
              "      <td>9.006</td>\n",
              "      <td>9.591</td>\n",
              "      <td>4.778</td>\n",
              "      <td>5.468</td>\n",
              "      <td>6.360</td>\n",
              "      <td>9.983</td>\n",
              "      <td>4.274</td>\n",
              "      <td>2.979</td>\n",
              "      <td>0.865</td>\n",
              "      <td>5.641</td>\n",
              "      <td>0.964</td>\n",
              "      <td>0.289</td>\n",
              "      <td>26.8</td>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100.4</td>\n",
              "      <td>118.6</td>\n",
              "      <td>142.9</td>\n",
              "      <td>31.453</td>\n",
              "      <td>0.224</td>\n",
              "      <td>0.105</td>\n",
              "      <td>0.060</td>\n",
              "      <td>4.894</td>\n",
              "      <td>2.497</td>\n",
              "      <td>2.650</td>\n",
              "      <td>0.469</td>\n",
              "      <td>10.015</td>\n",
              "      <td>7.685</td>\n",
              "      <td>6.376</td>\n",
              "      <td>2.866</td>\n",
              "      <td>9.133</td>\n",
              "      <td>9.708</td>\n",
              "      <td>4.889</td>\n",
              "      <td>5.510</td>\n",
              "      <td>6.444</td>\n",
              "      <td>10.182</td>\n",
              "      <td>4.420</td>\n",
              "      <td>2.964</td>\n",
              "      <td>0.830</td>\n",
              "      <td>5.637</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.281</td>\n",
              "      <td>24.3</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.4</td>\n",
              "      <td>118.1</td>\n",
              "      <td>142.2</td>\n",
              "      <td>32.190</td>\n",
              "      <td>0.243</td>\n",
              "      <td>0.117</td>\n",
              "      <td>0.061</td>\n",
              "      <td>4.946</td>\n",
              "      <td>2.503</td>\n",
              "      <td>2.695</td>\n",
              "      <td>0.477</td>\n",
              "      <td>10.053</td>\n",
              "      <td>7.765</td>\n",
              "      <td>6.394</td>\n",
              "      <td>2.877</td>\n",
              "      <td>9.101</td>\n",
              "      <td>9.676</td>\n",
              "      <td>4.855</td>\n",
              "      <td>5.500</td>\n",
              "      <td>6.416</td>\n",
              "      <td>10.115</td>\n",
              "      <td>4.347</td>\n",
              "      <td>3.725</td>\n",
              "      <td>0.835</td>\n",
              "      <td>4.823</td>\n",
              "      <td>0.969</td>\n",
              "      <td>0.290</td>\n",
              "      <td>24.1</td>\n",
              "      <td>17.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     T10    T50    T90      NA   C5NP  ...  C10IP   C10N   C10A  T90-T50  T50-T10\n",
              "0  100.5  119.2  146.5  31.978  0.272  ...  5.257  0.525  0.319     27.3     18.7\n",
              "1   99.6  117.9  145.5  31.568  0.297  ...  5.591  1.119  0.303     27.6     18.3\n",
              "2  100.0  118.8  145.6  31.344  0.262  ...  5.641  0.964  0.289     26.8     18.8\n",
              "3  100.4  118.6  142.9  31.453  0.224  ...  5.637  0.968  0.281     24.3     18.2\n",
              "4  100.4  118.1  142.2  32.190  0.243  ...  4.823  0.969  0.290     24.1     17.7\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNMV1HkvKIBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "1a634e0f-1ee9-4e40-e069-34933a533793"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T10</th>\n",
              "      <th>T50</th>\n",
              "      <th>T90</th>\n",
              "      <th>NA</th>\n",
              "      <th>C5NP</th>\n",
              "      <th>C5IP</th>\n",
              "      <th>C5N</th>\n",
              "      <th>C6NP</th>\n",
              "      <th>C6IP</th>\n",
              "      <th>C6N</th>\n",
              "      <th>C6A</th>\n",
              "      <th>C7NP</th>\n",
              "      <th>C7IP</th>\n",
              "      <th>C7N</th>\n",
              "      <th>C7A</th>\n",
              "      <th>C8NP</th>\n",
              "      <th>C8IP</th>\n",
              "      <th>C8N</th>\n",
              "      <th>C8A</th>\n",
              "      <th>C9NP</th>\n",
              "      <th>C9IP</th>\n",
              "      <th>C9N</th>\n",
              "      <th>C9A</th>\n",
              "      <th>C10NP</th>\n",
              "      <th>C10IP</th>\n",
              "      <th>C10N</th>\n",
              "      <th>C10A</th>\n",
              "      <th>T90-T50</th>\n",
              "      <th>T50-T10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98.6</td>\n",
              "      <td>119.2</td>\n",
              "      <td>146.1</td>\n",
              "      <td>40.133</td>\n",
              "      <td>1.142</td>\n",
              "      <td>0.616</td>\n",
              "      <td>0.217</td>\n",
              "      <td>3.745</td>\n",
              "      <td>2.577</td>\n",
              "      <td>4.028</td>\n",
              "      <td>0.557</td>\n",
              "      <td>7.669</td>\n",
              "      <td>5.9900</td>\n",
              "      <td>10.206</td>\n",
              "      <td>3.075</td>\n",
              "      <td>7.920</td>\n",
              "      <td>8.036</td>\n",
              "      <td>7.039</td>\n",
              "      <td>5.438</td>\n",
              "      <td>5.263</td>\n",
              "      <td>9.537</td>\n",
              "      <td>4.877</td>\n",
              "      <td>3.481</td>\n",
              "      <td>1.088</td>\n",
              "      <td>5.652</td>\n",
              "      <td>0.618</td>\n",
              "      <td>0.597</td>\n",
              "      <td>26.9</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>105.4</td>\n",
              "      <td>122.2</td>\n",
              "      <td>148.2</td>\n",
              "      <td>32.175</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.029</td>\n",
              "      <td>3.955</td>\n",
              "      <td>1.563</td>\n",
              "      <td>2.407</td>\n",
              "      <td>0.400</td>\n",
              "      <td>10.016</td>\n",
              "      <td>7.2633</td>\n",
              "      <td>6.573</td>\n",
              "      <td>2.809</td>\n",
              "      <td>9.544</td>\n",
              "      <td>9.815</td>\n",
              "      <td>5.135</td>\n",
              "      <td>5.482</td>\n",
              "      <td>6.793</td>\n",
              "      <td>10.850</td>\n",
              "      <td>4.308</td>\n",
              "      <td>3.963</td>\n",
              "      <td>1.069</td>\n",
              "      <td>6.025</td>\n",
              "      <td>0.585</td>\n",
              "      <td>0.484</td>\n",
              "      <td>26.0</td>\n",
              "      <td>16.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>105.8</td>\n",
              "      <td>122.7</td>\n",
              "      <td>149.2</td>\n",
              "      <td>31.428</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.020</td>\n",
              "      <td>3.920</td>\n",
              "      <td>1.447</td>\n",
              "      <td>2.296</td>\n",
              "      <td>0.396</td>\n",
              "      <td>10.236</td>\n",
              "      <td>7.3480</td>\n",
              "      <td>6.259</td>\n",
              "      <td>2.797</td>\n",
              "      <td>9.655</td>\n",
              "      <td>9.986</td>\n",
              "      <td>4.942</td>\n",
              "      <td>5.453</td>\n",
              "      <td>6.947</td>\n",
              "      <td>10.996</td>\n",
              "      <td>4.269</td>\n",
              "      <td>3.997</td>\n",
              "      <td>1.034</td>\n",
              "      <td>6.107</td>\n",
              "      <td>0.543</td>\n",
              "      <td>0.456</td>\n",
              "      <td>26.5</td>\n",
              "      <td>16.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>105.4</td>\n",
              "      <td>122.4</td>\n",
              "      <td>147.6</td>\n",
              "      <td>31.390</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.085</td>\n",
              "      <td>0.021</td>\n",
              "      <td>3.900</td>\n",
              "      <td>1.437</td>\n",
              "      <td>2.274</td>\n",
              "      <td>0.397</td>\n",
              "      <td>10.259</td>\n",
              "      <td>7.3560</td>\n",
              "      <td>6.234</td>\n",
              "      <td>2.820</td>\n",
              "      <td>9.670</td>\n",
              "      <td>10.146</td>\n",
              "      <td>4.928</td>\n",
              "      <td>5.476</td>\n",
              "      <td>6.953</td>\n",
              "      <td>11.026</td>\n",
              "      <td>4.264</td>\n",
              "      <td>3.982</td>\n",
              "      <td>1.013</td>\n",
              "      <td>6.054</td>\n",
              "      <td>0.545</td>\n",
              "      <td>0.449</td>\n",
              "      <td>25.2</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>105.4</td>\n",
              "      <td>122.6</td>\n",
              "      <td>148.2</td>\n",
              "      <td>32.418</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.049</td>\n",
              "      <td>0.015</td>\n",
              "      <td>3.873</td>\n",
              "      <td>1.369</td>\n",
              "      <td>2.206</td>\n",
              "      <td>0.489</td>\n",
              "      <td>10.213</td>\n",
              "      <td>7.3190</td>\n",
              "      <td>6.009</td>\n",
              "      <td>2.968</td>\n",
              "      <td>9.564</td>\n",
              "      <td>10.052</td>\n",
              "      <td>4.769</td>\n",
              "      <td>6.584</td>\n",
              "      <td>6.866</td>\n",
              "      <td>10.892</td>\n",
              "      <td>4.169</td>\n",
              "      <td>4.227</td>\n",
              "      <td>0.930</td>\n",
              "      <td>5.828</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.463</td>\n",
              "      <td>25.6</td>\n",
              "      <td>17.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     T10    T50    T90      NA   C5NP  ...  C10IP   C10N   C10A  T90-T50  T50-T10\n",
              "0   98.6  119.2  146.1  40.133  1.142  ...  5.652  0.618  0.597     26.9     20.6\n",
              "1  105.4  122.2  148.2  32.175  0.122  ...  6.025  0.585  0.484     26.0     16.8\n",
              "2  105.8  122.7  149.2  31.428  0.098  ...  6.107  0.543  0.456     26.5     16.9\n",
              "3  105.4  122.4  147.6  31.390  0.122  ...  6.054  0.545  0.449     25.2     17.0\n",
              "4  105.4  122.6  148.2  32.418  0.072  ...  5.828  0.519  0.463     25.6     17.2\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er41G27uKv0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "High_RMSE_index = ['C6N', 'C7N', 'C8N', 'C8A']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glO7MxZoK3HK",
        "colab_type": "text"
      },
      "source": [
        "# Ensembling & Stacking models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCdILfEQK1No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import (RandomForestRegressor, AdaBoostRegressor, \n",
        "                              GradientBoostingRegressor,ExtraTreesRegressor)\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Some useful parameters which will come in handy later on\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "SEED = 0 # for reproducibility\n",
        "NFOLDS = 5 # set folds for out-of-fold prediction\n",
        "kf = KFold(n_splits = NFOLDS ,random_state=SEED)\n",
        "\n",
        "# Class to extend the Sklearn classifier\n",
        "class SklearnHelper(object):\n",
        "    def __init__(self, clf,seed=0,params=None):\n",
        "        params['random_state'] = seed\n",
        "        self.clf = clf(**params)\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        self.clf.fit(x_train, y_train)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.clf.predict(x)\n",
        "    \n",
        "    def fit(self,x,y):\n",
        "        return self.clf.fit(x,y)\n",
        "    \n",
        "    def feature_importances(self,x,y):\n",
        "        print(self.clf.fit(x,y).feature_importances_)\n",
        "    \n",
        "# Class to extend XGboost classifer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEuVwHMmK_LV",
        "colab_type": "text"
      },
      "source": [
        "Out-of-Fold Predictions Now as alluded to above in the introductory section, stacking uses predictions of base classifiers as input for training to a second-level model. However one cannot simply train the base models on the full training data, generate predictions on the full test set and then output these for the second-level training. This runs the risk of your base model predictions already having \"seen\" the test set and therefore overfitting when feeding these predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_2RUiFWK7nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_oof(clf, x_train, y_train, x_test):\n",
        "    oof_train = np.zeros((ntrain,))\n",
        "    oof_test = np.zeros((ntest,))\n",
        "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
        "    for i, (train_index, test_index) in enumerate(kf.split(x_train)):\n",
        "        x_tr = x_train[train_index]\n",
        "        y_tr = y_train[train_index]\n",
        "        x_te = x_train[test_index]\n",
        "\n",
        "        clf.train(x_tr, y_tr)\n",
        "\n",
        "        oof_train[test_index] = clf.predict(x_te)\n",
        "        oof_test_skf[i, :] = clf.predict(x_test)\n",
        "\n",
        "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
        "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78DmDv69LCf5",
        "colab_type": "text"
      },
      "source": [
        "# Generating our Base First-Level Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4oGTVVhK-oV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random Forest parameters\n",
        "rf_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 500,\n",
        "     'warm_start': True, \n",
        "     #'max_features': 0.2,\n",
        "    'max_depth': 6,\n",
        "    'min_samples_leaf': 2,\n",
        "    'max_features' : 'sqrt',\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# Extra Trees Parameters\n",
        "et_params = {\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators':500,\n",
        "    #'max_features': 0.5,\n",
        "    'max_depth': 8,\n",
        "    'min_samples_leaf': 2,\n",
        "    'verbose': 0\n",
        "}\n",
        "\n",
        "# AdaBoost parameters\n",
        "ada_params = {\n",
        "    'n_estimators': 500,\n",
        "    'learning_rate' : 0.75\n",
        "}\n",
        "\n",
        "# Gradient Boosting parameters\n",
        "gb_params = {\n",
        "    'n_estimators': 500,\n",
        "     #'max_features': 0.2,\n",
        "    'max_depth': 5,\n",
        "    'min_samples_leaf': 2,\n",
        "    'verbose': 0\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5kvpVcLD4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf = SklearnHelper(clf=RandomForestRegressor,seed=SEED,params=rf_params)\n",
        "et = SklearnHelper(clf=ExtraTreesRegressor,seed=SEED,params=et_params)\n",
        "ada = SklearnHelper(clf=AdaBoostRegressor,seed=SEED,params=ada_params)\n",
        "gb = SklearnHelper(clf=GradientBoostingRegressor,seed=SEED,params=gb_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IclOfRw9LHcv",
        "colab_type": "text"
      },
      "source": [
        "# define y_name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl3jrtktLFhI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ba2bfcb9-1df0-40fb-939d-a861e049feb8"
      },
      "source": [
        "High_RMSE_index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C6N', 'C7N', 'C8N', 'C8A']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKuvvbH5LJij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_name = 'C6N'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzM8goIiLLFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2302d222-f90f-4f21-a22f-defe2bb9d91b"
      },
      "source": [
        "y_train = train[y_name].ravel()\n",
        "y_test = test[y_name].ravel()\n",
        "\n",
        "x_train = train[x_columns].values \n",
        "x_test = test[x_columns].values\n",
        "\n",
        "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4521, 6) (170, 6) (4521,) (170,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2ypaqYxLOOZ",
        "colab_type": "text"
      },
      "source": [
        "# Output of the First level Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zftgmpoLP5x",
        "colab_type": "text"
      },
      "source": [
        "We now feed the training and test data into our 5 base classifiers and use the Out-of-Fold prediction function we defined earlier to generate our first level predictions. Allow a handful of minutes for the chunk of code below to run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em4LDCRoLMTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "4d335318-bd8c-440a-9ccf-440b9a69efd4"
      },
      "source": [
        "et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test) # Extra Trees\n",
        "rf_oof_train, rf_oof_test = get_oof(rf,x_train, y_train, x_test) # Random Forest\n",
        "ada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test) # AdaBoost \n",
        "gb_oof_train, gb_oof_test = get_oof(gb,x_train, y_train, x_test) # Gradient Boost\n",
        "\n",
        "print(\"Training is complete\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
            "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
            "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
            "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:307: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
            "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training is complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxuwwGvfLRiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "db375db4-9a6e-4ed1-e3b0-ceb77015a6e2"
      },
      "source": [
        "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
        "     'ExtraTrees': et_oof_train.ravel(),\n",
        "     'AdaBoost': ada_oof_train.ravel(),\n",
        "      'GradientBoost': gb_oof_train.ravel()\n",
        "    })\n",
        "base_predictions_train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RandomForest</th>\n",
              "      <th>ExtraTrees</th>\n",
              "      <th>AdaBoost</th>\n",
              "      <th>GradientBoost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.589772</td>\n",
              "      <td>2.654719</td>\n",
              "      <td>3.517362</td>\n",
              "      <td>2.438679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.091172</td>\n",
              "      <td>3.005278</td>\n",
              "      <td>3.517362</td>\n",
              "      <td>3.083808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.794150</td>\n",
              "      <td>2.736394</td>\n",
              "      <td>3.517362</td>\n",
              "      <td>2.303332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.785535</td>\n",
              "      <td>2.725557</td>\n",
              "      <td>3.517362</td>\n",
              "      <td>2.068550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.859695</td>\n",
              "      <td>2.906079</td>\n",
              "      <td>3.517362</td>\n",
              "      <td>2.359137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RandomForest  ExtraTrees  AdaBoost  GradientBoost\n",
              "0      2.589772    2.654719  3.517362       2.438679\n",
              "1      3.091172    3.005278  3.517362       3.083808\n",
              "2      2.794150    2.736394  3.517362       2.303332\n",
              "3      2.785535    2.725557  3.517362       2.068550\n",
              "4      2.859695    2.906079  3.517362       2.359137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg7XoKnhLheR",
        "colab_type": "text"
      },
      "source": [
        "# Correlation Heatmap of the Second Level Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_au0u6LLjS_",
        "colab_type": "text"
      },
      "source": [
        "There have been quite a few articles and Kaggle competition winner stories about the merits of having trained models that are more uncorrelated with one another producing better scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-4CF97gLf04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "4b4db49a-c77b-4549-b96b-8e44acaf3b24"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(abs(base_predictions_train.astype(float).corr()),\n",
        "            annot=True,\n",
        "            linewidths=0.1,\n",
        "            cmap=\"YlGnBu\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6dd0e190b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAD8CAYAAAA1+KBcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8FdX9//HXO2GXVZaAsimLoqAg\nCLihgoAo7vpVvrViv7V8ca1WbK1aRVoVqq2ty1fEVlHrT7GoFFnEiCAugIAgyCKbyh4QDLIKJJ/f\nHzMJNzHLDSSZm+vnyWMezJxzZubM3Jv53HPm3LkyM5xzzrmopERdAeeccz9tHoicc85FygORc865\nSHkgcs45FykPRM455yLlgcg551ykPBA555zLQ9LzkjZL+qKQfEl6QtJKSQslnRKTN1DSinAaGM/+\nPBA555zLbzRwfhH5/YA24TQIeAZA0pHAA0A3oCvwgKR6xe3MA5Fzzrk8zGwGsK2IIpcAL1lgFlBX\nUhOgL5BuZtvM7DsgnaIDGgCVSqPSrlD+2ArnXLx0OCtXbz4g7uvN3rWv/S9BSybHKDMbVYLdHQ2s\njVleF6YVll4kD0RlqHrzAVFXISHsWfMqrTr/LepqJIRV824nc9/kqKuREOpW6Uer68ZEXY2EsOql\nq8t1f2HQKUngKVPeNeecc0lASol7KgXrgWYxy03DtMLSi+SByDnnkkCKKsU9lYLxwHXh6LnuwHYz\n2whMAfpIqhcOUugTphXJu+accy4JlFJLJ9yWXgXOARpIWkcwEq4ygJmNBCYBFwArgd3AL8K8bZL+\nCMwJNzXMzIoa9AB4IHLOuaQgHdZYhzzMrMgb3Bb8ftDNheQ9Dzxfkv15IHLOuaRQce+0eCByzrkk\nUJpdc+XNA5FzziUBD0TOOeciVUqj4SJRcWvunHMul7eInHPORcoDkXPOuUjp8B5VFykPRM45lwS8\nReSccy5SKSkV93JecWvunHMuhreInHPORci75pxzzkXKA5FzzrlIybvmnHPORclbRM455yKVkpIa\ndRUOmQci55xLAt4155xzLlLeNecSzshH/5d+vTqxZev3dOn926irU+Z6nNaCPww5m9TUFMaM+4Jn\nR8/Nk39U41qMeKA3R9arTub2H7jzD++wafNOundpyr2/OTu3XKuW9fj1PZNJn76qvA+h1Mz8aCl/\nHfEm2VnGxZd3Z+AN5+XJf3zEW8ybswKAvXv38922HUz9ZHhu/s6de7nmkkc4u2cH7rr3ynKte2nr\n0aExf7i2E6kpYswHq3l2wrI8+UfVr8GIG7pyZK2qZO7ax50jZ7Hpuz0cVb8Gz/z6TFIElVJTeCl9\nBa9OS+z3RFIHIklZwKKw7FfAz80s83B3LKklMMHM2pfCtkYDZwPbw6TnzeyJw91uIfs6B9hnZp+U\nxfZLy8v//oCRL07hH4/fFHVVylxKihh697kMvOlNNmXs5K2XBzD1g9Ws/Gpbbpnf33EWb01cypsT\nlnLaqU0ZcssZDLl/CrPmruOi/34FgDq1q/L+uF/w4axvojqUw5aVlc2jD43lyVE30qhxXa6/5q+c\ndW57jm3VOLfMHb+7LHf+9Vdm8OWydXm28exTk+jUuVW51bmspEgMva4zA/88nU3b9vDWg72Z+tkG\nVm74PrfM7wd05K2Pv+bNj77mtHaNGPJfJzHk2dlsydzLVcPeY9+BbGpUrcTkh89n6vz1bM7cG+ER\nFa0id83FU/M9ZtYxDBjbKOR3yhPAXWE9O5YkCEkq6R2+c4DTS7hOufv402Vsy9wZdTXKxcknNuab\ntdtZu/579h/IZsK7yznvnLwX0tbH1GfmnLUAzJyzjvPOPvZH2+nXqw0ffPI1e/ceKJd6l4Uli76h\nafMGHN2sAZUrV6J3v07MmLao0PLvTv6MPv065y4vXbyWbVt30O3048qjumXq5FZH8s3mHazdsov9\nWdlMmLWG8045Ok+Z1kfVZuaSDABmLt2cm78/K5t9B7IBqFI5hZQKcI1XSqW4p0RT0tM7EzgaQFJN\nSVMlfSZpkaRLwvSWkpZKek7SYknvSqoe5nWW9Lmkz4kJaJKqSXoh3M58SeeG6ddLGicpXdLXkm6R\n9JuwzCxJRxZVWUkDwm1+IWlETPpOSX8J63FaWK8PJM2TNEVSk7DcbZKWSFoo6bWwFTcYuEPSAkln\nlfD8uTKQ1ugINmbsyF3elLGDtIZH5CmzbMUW+vZsDUCfc1tRq2ZV6taplqdM/77H8faUL8u+wmVo\n8+btpDWul7vcKK0uWzK2F1h244ZtbFi/jS7d2gCQnZ3NE4+N47Y7LymXupa1tHrV2bh1T+7ypm27\nSatXPU+ZZWsz6dulKQB9uhxNreqVqVuzCgBNjqzOxD/15aPHL+LZCcsSujUEICnuKdHEHYjClkMv\nYHyYtBe4zMxOAc4F/qKDR9gGeNrMTgQygSvC9BeAW83s5HybvxkwM+sADABelJRzlWgPXA6cCjwE\n7DazTgRB8bqYbTwaBocFkjpIOgoYAfQEOgKnSro0LHsEMDusx2zgSeBKM+sMPB/uB+BuoJOZnQQM\nNrOvgZHA42HL68N4z5+L1iOPf0jXU5oy/pX/plvnpmzM2EFWluXmN2xQg7at6/PhzIrbLVdS6ZM/\no2fvk0lNDS4Db7z2MaefdQJpjetGXLPy88irC+h6fCPG/7EP3Y5rxMZtu8nKDt4XG7ft4cL7ptDz\nrolcfmZL6teuGnFtiyZS4p4STTxttOqSFhC0hJYC6WG6gIcl9QCyw/y0MO8rM1sQzs8DWkqqC9Q1\nsxlh+stAv3D+TIJggJktk/QN0DbMm2ZmO4AdkrYDb4fpi4CTYup5l5mNzVkIW2jTzWxLuPwK0AMY\nB2QBb4RFjyMIdulhHE0FNoZ5C4FXJI0L1yuWpEHAIIBK9bpQqWbreFZzhyFj8y6apNXKXW6cVouM\nLbvylNn87S5uumsCADWqV6Zvz9bs2PlDbv6FvduSPm0VB8LumIqqUaM6ZGz6Lnd5c0YmDdPqFFg2\n/Z35eQYjLPr8axZ8too3xnzE7t372L//ADVqVOXmOy4q83qXhYzv9tCk/sEWUOMja5Dx3Z48ZTZn\n7uWmJz4GoEbVSvQ9tSk7du//UZnl67dz6nENeWdO3vtpiaQiD1aI+x4R0IIg+OR0qf0MaAh0DvMz\ngJxWzA8x62dxeKPzYreVHbOcfRjb3WtmWeG8gMUx95c6mFmfMO9C4GngFGCOVPyPwpvZKDPrYmZd\nPAiVj4VLNtGyWV2aHlWbypVS6N+nLVM/yDvCqV7dauS012/8xamMHb84T34ydMsBtGvfnLXffMuG\ndVvZv/8A6ZPn0+OcH48H+np1Bju+302Hk1vmpg0b8XPGpw9l3JQHuO3Oi7ngolMrbBACWLh6Gy3T\natG0wRFUTk2hf/fmTJ2/Pk+ZejWrHHxfXNSOsTO+AqBxvepUrRzcPq5dozJd2jZk9cYdJDQp/inB\nxH0hN7Pdkm4Dxkn6P6AOsNnM9of3dFoUs36mpExJZ5rZRwSBLMeH4fL7ktoCzYEvCQLAofoUeEJS\nA+A7gi6/Jwso9yXQUNJpZjZTUmWC1thSoJmZTZP0EXANUBPYAdQ+jHqVixefvJWzTmtHg3q1WDn7\nKf7417G8OGZ61NUqE1lZxoN/nsbopy4jJVWM/c9iVqzexu2Du7NoyWamzlhNt85NueuWMzCDT+ev\nZ+jwabnrH92kNk3SajF7XuJ+2o1XpUqpDLnnCm4bPJLsrGwuuqwbx7ZuwrNPTaLdic3pcW4QlNLf\n+Yze55+SkPcLSktWtvHgS58x+rdnkyIxdsZqVqz/ntsvb8+ir7Yxdf4GurVrxF1XnYQBny7bwtCX\n5gHQ6qja3DOgI0bwSfUfk5axfF3B99oSRsVtECEzK7qAtNPMasYsvw28Dkwm6CarCcwFunOwqy13\nWLakIUBNMxsqKecejAHvAheYWfvwftAzQBfgAPCbMABcD3Qxs1vCbX0dLn8bmxcO354Q2zUXlh8A\n3EPwXppoZr8r5Jg6Ak8QBNdKwN+A0cC0ME3Av8xseBgoxxK0yG4t6j5R9eYDij65PxF71rxKq85/\ni7oaCWHVvNvJ3Dc56mokhLpV+tHqujFRVyMhrHrpauDwfuu77ekj477eLP9kcEJ9Aomnq6lmvuXY\ntvpphayW2xdgZo/FzM8DYgcq/DZM3wv8ooB9jyYICDnLLQvKM7PrC6n7q8CrBaTnP6YFBPeP8juz\ngHWXk/felHPORa8Ct4gSb0C5c865ErMK3M1agWOoc865XCrBFM/mpPMlfSlppaS7C8hvEX6XdKGk\n6ZKaxuRlxXydZnz+dfPzFpFzziWDlNJrEYXfG30a6A2sIxg1PN7MlsQUewx4ycxelNQTeAT4eZiX\nM9o6Lt4ics65ZFC6w7e7AivNbLWZ7QNeA/I/cuME4P1wfloB+XHzQOScc8kgVXFPkgZJmhszDcq3\ntaOBtTHL68K0WJ8TPPUG4DKglqT64XK1cLuzYp5oUyjvmnPOuWRQgsEKZjYKGHWYexwCPBV+lWYG\nsJ7gAQYALcxsvaRjCb4fusjMCv0dDQ9EzjmXDEp30Nx6oFnMctMwLZeZbSBsEUmqCVyR8xNBZrY+\n/H+1pOlAJ6DQQORdc845lwxSFP9UvDlAG0nHSKpC8GSZPKPfJDXQwQfc/Z7gYQVIqiepak4Z4Awg\ndpDDj6teogN1zjmXmEpx+LaZHQBuAaYQPO7sdTNbLGmYpIvDYucAX0paTvDA65xfLWgHzA1/Zmca\nMDzfaLsf8a4555xLApZauu0KM5sETMqXdn/M/FiCx53lX+8ToENJ9uWByDnnkkHFfbCCByLnnEsK\nFfgRPx6InHMuGZTikxXKmwci55xLBhU3Dnkgcs65pOBdc8455yKV6oHIOedclLxF5JxzLlIVNw55\nIHLOuWRgPmrOOedcpLxrzjnnXKQqbhxCZhZ1HZKZn1znXLwOK5S0um5M3NebVS9dnVBhy1tEZahV\n579FXYWEsGre7VRvPiDqaiSEPWteJXPfpOIL/gTUrXIBrfuPjroaCWHlhOsPfyMJFVpKxgORc84l\nAx+s4JxzLlIeiJxzzkXJKm4c8kDknHNJoZR/GK88eSByzrlk4F1zzjnnIlVxG0QeiJxzLin4kxWc\nc85FyrvmnHPORcm8ReSccy5SlTwQOeeci5K3iJxzzkXK7xE555yLVMWNQx6InHMuGfgvtDrnnItW\nBQ5EFfi7uM4553KlKv4pDpLOl/SlpJWS7i4gv4WkqZIWSpouqWlM3kBJK8JpYHH78kDknHPJQIp/\nKnZTSgWeBvoBJwADJJ2Qr9hjwEtmdhIwDHgkXPdI4AGgG9AVeEBSvaL254HIOeeSQYrin4rXFVhp\nZqvNbB/wGnBJvjInAO+H89Ni8vsC6Wa2zcy+A9KB84usepyH6JxzLpGVIBBJGiRpbsw0KN/WjgbW\nxiyvC9NifQ5cHs5fBtSSVD/OdfPwwQrOOZcESvKIHzMbBYw6zF0OAZ6SdD0wA1gPZB3KhjwQOedc\nMohzEEKc1gPNYpabhmm5zGwDYYtIUk3gCjPLlLQeOCffutOL2pl3zTnnXDIo3XtEc4A2ko6RVAW4\nBhgfW0BSA0k5MeT3wPPh/BSgj6R64SCFPmFaobxFVIH1OK0FfxhyNqmpKYwZ9wXPjp6bJ/+oxrUY\n8UBvjqxXncztP3DnH95h0+addO/SlHt/c3ZuuVYt6/HreyaTPn1VeR9CuRj56P/Sr1cntmz9ni69\nfxt1dcrczI+W8tcRb5GdZVx8eTcG3nBenvzHR7zFvDkrAdi7dz/fbdvB1E8eyc3fuXMv11wynLN7\nduCue68o17qXth6nHM19g7qSmiJef3cFz45dlCf/qIZHMPz2MziydjW279zHnY/NYNPW3bn5NatX\n5p1nLiV91hoeHDm7vKtfMqX4PSIzOyDpFoIAkgo8b2aLJQ0D5prZeIJWzyOSjKBr7uZw3W2S/kgQ\nzACGmdm2ovZXroFIUhYQ+054zcyGF1H+HjN7uIT7eAs4BqgJNAS+CrNuMrNPSljlhJWSIobefS4D\nb3qTTRk7eevlAUz9YDUrvzr4ev/+jrN4a+JS3pywlNNObcqQW85gyP1TmDV3HRf99ysA1KldlffH\n/YIPZ30T1aGUuZf//QEjX5zCPx6/KeqqlLmsrGwefegNnhw1mEaN63L9NY9z1rntObZV49wyd/zu\nstz511+ZwZfL8vS48OxTk+jUuVW51bmspKSIoTd2Y+B977Jp627efLw/U2evYeXa7bllfv/LU3lr\n6ireen8V3U9qzJCBnRny1w9z82//eSc+/SIjiuqXXCl/n9XMJgGT8qXdHzM/FhhbyLrPc7CFVKzy\n7prbY2YdY6ZCg1DonoISFSiw7mZ2mZl1BG4APozZ1yf5tlGhW4Mnn9iYb9ZuZ+3679l/IJsJ7y7n\nvHPyXjxaH1OfmXOCwSsz56zjvLOP/dF2+vVqwweffM3evQfKpd5R+PjTZWzL3Bl1NcrFkkVraNq8\nAUc3a0DlypXo3a8TM6Z9UWj5dyfPp0+/U3KXly5ey7atO+l2+nHlUd0ydXLbBnyzcQdrM3ay/0A2\nE2d8xXndm+cp07pZHWYt3AjArIWbOK/7wdsiJ7aqT4O61flo/oZyrfehshTFPSWayO8RSaoTfnv3\nuHD5VUm/kjQcqC5pgaRXJLUMy70EfAE0k/RMOPRwsaQH49jXOknDJc0HLpPURtIUSfMkzZDUNiyX\nJunNcNufSuoepveU9HlYp88kHVF2Z6ZoaY2OYGPGjtzlTRk7SGuYtzrLVmyhb8/WAPQ5txW1alal\nbp1qecr073scb0/5suwr7MrF5s2ZpDWum7vcKK0OWzK2F1h244ZtbFi/lS7d2gCQnZ3NE4/9h9vu\nvLhc6lrW0urXYOOWXbnLm77dRVr9GnnKLP3qO/qc3gKAPqc1p2aNKtStVRUJ7rnhVIb/cw4VRil+\nobW8lXeroLqkBTHLj5jZmLAvcrSkvwP1zOw5AEm3hK0bJLUE2gADzWxWmHZv2B+ZCkyVdJKZLSym\nDpvNrFO4/jTgBjNbJekM4CmCG2tPAH82s1nhficA7YG7gEFmNjscJbI3/8bD8fiDABo0v4raDU4v\n6TkqNY88/iFDf3cul/c/gTnz17MxYwdZWZab37BBDdq2rs+HM5O3W84VLn3yfHr2PpnU1ODz6Buv\nfczpZ7XLE8iS3fDn5/DA4O5c0as1ny7OYNO3u8jKNq698Himz12X535RwivdUXPlqrwD0Z6cwBLL\nzNIlXUXwSImTi1j/m5wgFPqv8MJfCWhC8E3f4gLRGABJdYHuwBs6+Akh53ycBxwXk15PUnXgY+Dv\nkl4B3jCzH/X3xI7Pb9X5b5Y/v7RkbN5Fk7RaucuN02qREfPpD2Dzt7u46a4JANSoXpm+PVuzY+cP\nufkX9m5L+rRVHDiQXVbVdOWsUaO6ZGzKzF3enLGdhml1Ciyb/s78PIMRFn3+NQs+W80bYz5m9+59\n7N9/gBo1qnDzHReVeb3LQsbW3TSJ6SVo3OAIMvIFls3b9nDzw9MAqFGtEuef3oIdu/bR8fiGnHpC\nGj+74HhqVKtElcop7N5zgEdfnFeux1ASKZH3bx26hLhPEt7vaQfsBuoRfBO3ILti1jmG4AtVp5rZ\nd5JGA9UKWa+gbQj4tqDAGOZ1DR9tEetPksYDFwKzJPUysxVx7LPULVyyiZbN6tL0qNpkbN5J/z5t\nuePeyXnK1KtbjcztezGDG39xKmPHL86T37/vcTz21MflWW1Xxtq1b8bab7awYd1WGqbVIX3yfP44\n4toflft6dQY7vt9Nh5Nb5qYNG/Hz3PkJ4z5l6eK1FTYIASxc/i0tjqpN07SaZGzdzYU9juE3j87I\nU6Ze7apk7vgBMxh8VQf+nR78Od/52MEBC5f3ak2HNvUTOghBQva4xS1RYugdwFLgv4EXJFUO0/fH\nzOdXmyCobJeURvBwvriFz0DaKOkyCIKhpJzW2HuEQxHDvJzuwVZmttDMHgE+AyK7o5uVZTz452mM\nfuoyprxxHZPSl7Ni9TZuH9ydXj2CQQndOjflvTcH8t6bA6lfvwb/F9PffXST2jRJq8XseYXF/OTx\n4pO3Mn3cMNoe24SVs59i4NXnRF2lMlOpUipD7rmC2wY/y9UXD+e8vh05tnUTnn1qcp5BC+nvzKf3\n+Z1QRb56FSMr23hw5CxeGNabKc9cyqQPv2bFmkx+/bOO9OoaDEro1qEx6c9eTvqzl9GgbnWeGVNc\nh0riqsC3iJBZmfUe/XhnPx6+/Q7wAjCOoAWyQ9JfgR1m9oCkEcDFBBf9e4EJZtY+ZnujgdMJnmu0\nHRhvZqPDvHOAIWbWP6b8OqC9mWWGy8cCzwCNgSrAv8zsIUkNw/S2BK3GaWZ2s6RngLOAbIIuwP8p\noNWUqyy75iqSVfNup3rzAVFXIyHsWfMqmfsmFV/wJ6BulQto3X901NVICCsnXA+HOQC71TMz4r7e\nrLqxR0KFo3LtmjOz1EKy2sWU+U3M/O+A38WUax+7kpldX8S+ppPvsRJm1jTf8mqCJ8XmX3cLcGUB\n6TcWtj/nnIuS3yNyzjkXqYK/WVkxeCByzrkkkIj3fuLlgcg555JAAj4wIW4eiJxzLgl4i8g551yk\nPBA555yLVIo/4sc551yUvEXknHMuUh6InHPORcoDkXPOuUj58G3nnHOR8haRc865SPmoOeecc5Hy\nFpFzzrlIeSByzjkXKQ9EzjnnIuWj5pxzzkUqpbCfHa0APBA551wS8K4555xzkVIFjkQeiJxzLglU\n4DhEBf6Vc+ecczmk+Kf4tqfzJX0paaWkuwvIby5pmqT5khZKuiBMbylpj6QF4TSy2H2ZWUmP18XP\nT65zLl6H1aY5d9LHcV9vpl1wRpH7kpQKLAd6A+uAOcAAM1sSU2YUMN/MnpF0AjDJzFpKaglMMLP2\n8dbHu+bKUOa+yVFXISHUrdKPzH2Toq5GQqhb5QKqNx8QdTUSwp41rxJc6xy0PewtVCrd/q2uwEoz\nWw0g6TXgEmBJTBkDaofzdYANh7oz75pzzrkkkCKLe5I0SNLcmGlQvs0dDayNWV4XpsUaClwraR0w\nCbg1Ju+YsMvuA0lnFVd3bxE551wSKMkXWs1sFDDqMHc5ABhtZn+RdBrwsqT2wEaguZltldQZGCfp\nRDP7vrANeYvIOeeSQEoJpjisB5rFLDcN02L9EngdwMxmAtWABmb2g5ltDdPnAasopu/RA5FzziWB\nknTNxWEO0EbSMZKqANcA4/OVWQP0ApDUjiAQbZHUMBzsgKRjgTbA6qJ25l1zzjmXBErzWXNmdkDS\nLcAUIBV43swWSxoGzDWz8cCdwHOS7iAYuHC9mZmkHsAwSfuBbGCwmW0ran8eiJxzLglUKuUvtJrZ\nJIJBCLFp98fMLwHOKGC9N4A3SrIvD0TOOZcEFF+XW0LyQOScc0nAfwbCOedcpCryyDMPRM45lwTi\nHA2XkDwQOedcEijtwQrlyQORc84lAb9H5JxzLlLeNeeccy5S3iJyzjkXKR8155xzLlLeNeeccy5S\npfzDeOXKA5FzziWBChyHPBA551wy8K4555xzkfJRc8455yLlXXMuEjM/WspfR7xJdpZx8eXdGXjD\neXnyHx/xFvPmrABg7979fLdtB1M/GZ6bv3PnXq655BHO7tmBu+69slzrXtqCc/FWeC66FXIuVgKx\n5+KR3PzgXAwPz8UV5Vr38jTy0f+lX69ObNn6PV16/zbq6pSrGTPm8dBDz5Gdnc1VV/Vm0KCr8uQ/\n/PBzzJ69CIC9e39g69btzJ37WhRVPSTeIioFki4F3gLamdmyAvJHAxPMbGwR2xgNnA1sJ/jZ2lfN\n7MFSruPy8AehIpWVlc2jD43lyVE30qhxXa6/5q+cdW57jm3VOLfMHb+7LHf+9Vdm8OWydXm28exT\nk+jUuVW51bmsBOfiDZ4cNTg8F4/HcS7W59lGspyL4rz87w8Y+eIU/vH4TVFXpVxlZWUxbNhIXnjh\nj6Sl1efKK39Dz57daN26eW6Ze+75Ve78yy+/zZIlRf66dcJJTam494gSqTU3APgo/P9w3GVmHYGO\nwEBJxxx2zQ66FDihFLd3yJYs+oamzRtwdLMGVK5cid79OjFj2qJCy787+TP69Oucu7x08Vq2bd1B\nt9OPK4/qlqkli9YUcC6+KLT8u5Pn06ffKbnLwbnYmRTnojgff7qMbZk7o65GuVu4cAUtWjShWbPG\nVKlSmQsv7MHUqbMLLT9x4gz69+9RjjU8fCklmBJNQtRJUk3gTOCXwDVhmiQ9JelLSe8BjWLK3y9p\njqQvJI2SVFCjtFr4/65wnV6S5ktaJOl5SVWLSR8uaYmkhZIek3Q6cDHwqKQFkiL9+Lx583bSGtfL\nXW6UVpctGdsLLLtxwzY2rN9Gl25tAMjOzuaJx8Zx252XlEtdy9rmzZmkNa6bu9worU4x52JrvnPx\nH2678+JyqauLRkbGVho3bpC7nJZWn4yMrQWWXb9+M+vWZdC9+0nlVb1SkSKLe0o0CRGIgEuAd8xs\nObBVUmfgMuA4ghbIdcDpMeWfMrNTzaw9UB3oH5P3qKQFwDrgNTPbLKkaMBq42sw6EHRJ3lhEev1w\n/yea2UnAn8zsE2A8YYvLzFYVdCCSBkmaK2nu6H9MLo1zc9jSJ39Gz94nk5oavNxvvPYxp591Qp6L\n909F+uT5BZyLdj/Jc+EKNnHiDPr2PYPU1NSoq1IiKYp/SjSJco9oAPD3cP61cLkSwT2eLGCDpPdj\nyp8r6bdADeBIYDHwdph3l5mNDVtZU8OWzC7gqzDQAbwI3AxMKyT9KWAv8E9JE4AJ8R6ImY0CRgFk\n7ptcZh89GjWqQ8am73KXN2dk0jCtToFl09+Zn2cwwqLPv2bBZ6t4Y8xH7N69j/37D1CjRlVuvuOi\nsqpumWrUqC4ZmzJzlzdnbC/mXBwcjBCci9W8MebjmHNRpcKeC1ewtLT6bNr0be5yRsZW0tLqF1h2\n0qQPuf/+weVVtVKTiAEmXpEHIklHAj2BDpIMSAWMYOBCQeWrAf8HdDGztZKGcrAbLpeZ7ZQ0naDL\nb0pJ6mRmByR1BXoBVwK3hHU8FiWdAAAY20lEQVRMGO3aN2ftN9+yYd1WGqbVIX3yfP444uc/Kvf1\n6gx2fL+bDie3zE0bFlNuwrjZLF28tkJfeNu1b8bab7bkOxfX/qhc8efi0wp/LlzBOnRow9dfb2Dt\n2k2kpdVn4sQZ/OUvQ35UbtWqtXz//U46dTo+gloensoJ2OUWr0TomrsSeNnMWphZSzNrBnwFbAWu\nlpQqqQlwblg+J+h8G7Z6Chx3LKkS0A1YBXwJtJTUOsz+OfBBYenhduuY2STgDuDkMH8HUKtUjvow\nVaqUypB7ruC2wSO5+uJHOK9vR45t3YRnn5qU50Z9+juf0fv8Uyj4NlpyOHgunuXqi4fHnIvJ+c7F\nfHqf3ympz0VxXnzyVqaPG0bbY5uwcvZTDLz6nKirVC4qVUrl/vsHc8MND3DBBTfRr9+ZtGnTgr//\n/V95Bi1MmvQhF1xwVoV8j1TkrjmZRRtFJU0DRpjZOzFptwHtgCygN7AG2A88H3a7/Ymg+24TsBz4\nxsyG5hu+XQWYCtxmZiapF/AYQStwDnCjmf1QUDpBd99/CIKegMfM7EVJZwDPAT8AVxZ2nyhHWXbN\nVSR1q/Qjc9+kqKuREOpWuYDqzQ93YGhy2LPmVYI/XwdtIbjWHLI/L0yP+3rz25N6J1Q4irxrzszO\nLSDtiWLWuQ+4r4D064tYZyrQKc70jUDXAsp+TIIM33bOuVipCRVaSibyQOScc+7wJWKXW7w8EDnn\nXBJIxO8HxSsRBis455w7TJUV/xQPSeeHDxRYKenuAvKbS5oWPhBgoaQLYvJ+H673paS+xe3LW0TO\nOZcESrNrTlIq8DTBYLF1wBxJ4/M9Z/M+4HUze0bSCcAkglHIJxA8IedE4CjgPUltw++EFlz30qu6\nc865qJTyI366AivNbLWZ7SN40ED+Z4IZUDucrwNsCOcvIXiqzQ9m9hWwkgIGf8XyFpFzziWBUh41\ndzSwNmZ5HcH3MmMNBd6VdCtwBJDz2ytHA7PyrXt0UTvzFpFzziWBknyhNfaZmOE06BB2OQAYbWZN\ngQuAlyUdUkzxFpFzziWBSiUIAbHPxCzEeqBZzHLTMC3WL4Hzw+3NDB+/1iDOdfPwFpFzziWBVFnc\nUxzmAG0kHSOpCsHgg/H5yqwheB4nktoRPIlmS1juGklVw9+DawN8WtTOvEXknHNJoDRbFeGDn28h\neGB0KsHj1RZLGgbMNbPxwJ3Ac5LuIBi4cL0Fz4xbLOl1YAlwALi5qBFz4IHIOeeSQmk/WSF86POk\nfGn3x8wvAc4oZN2HgIfi3ZcHIuecSwL+iB/nnHORivPeT0LyQOScc0mgJKPmEo0HIuecSwLeNeec\ncy5S/ntEzjnnIlWRfwbCA5FzziWBCnyLyAORc84lA79H5JxzLlKVU7xrzjnnXIQqcotIwaOBXBnx\nk+uci9dhhZKZmyfGfb05rdGFCRW2vEVUhlpdNybqKiSEVS9dTev+o6OuRkJYOeF6YHnU1UgQbane\nfEDUlUgIe9a8etjb8MEKzjnnIqWEauOUjAci55xLAhX5HpEHIuecSwLeNeeccy5S8icrOOeci1IF\n7pnzQOScc8nABys455yLVAWOQx6InHMuGfjPQDjnnIuUd80555yLVAWOQx6InHMuGXggcs45Fyl/\nsoJzzrlIVeA45IHIOeeSQYo/WcE551yUfNScc865SFXkh55W5Lo755wLSfFP8W1P50v6UtJKSXcX\nkP+4pAXhtFxSZkxeVkze+OL25S0i55xLAqXZMycpFXga6A2sA+ZIGm9mS3LKmNkdMeVvBTrFbGKP\nmXWMd3/eInLOuSSQovinOHQFVprZajPbB7wGXFJE+QHAIf/euQci55xLAiUJRJIGSZobMw3Kt7mj\ngbUxy+vCtB+R1AI4Bng/JrlauN1Zki4tru7eNeecc0mgJF1zZjYKGFVKu74GGGtmWTFpLcxsvaRj\ngfclLTKzVYVtwANRBdajQ2P+cG0nUlPEmA9W8+yEZXnyj6pfgxE3dOXIWlXJ3LWPO0fOYtN3eziq\nfg2e+fWZpAgqpabwUvoKXp1W6HukQuhxytHcN6grqSni9XdX8OzYRXnyj2p4BMNvP4Mja1dj+859\n3PnYDDZt3Z2bX7N6Zd555lLSZ63hwZGzy7v6ZWbGjHk89NBzZGdnc9VVvRk06Ko8+Q8//ByzZwfn\nau/eH9i6dTtz574WRVXL3chH/5d+vTqxZev3dOn926irc9hK+Rda1wPNYpabhmkFuQa4OTbBzNaH\n/6+WNJ3g/lGhF5m4u+YkpUn6f5JWS5onaaaky+Jdv4DtDZU0JJwfJum8Q9xOR0kXxCxfL2lLOFpj\nsaSxkmocaj2L219UUiSGXteZ/3lsBn3vfoeLureg9VG185T5/YCOvPXx11x43xSeGreYIf91EgBb\nMvdy1bD3uOgP73LFg+8xuH87GtWtFsVhlIqUFDH0xm788oF0zr9pHP3PPobWzerkKfP7X57KW1NX\n0f/W8Tz56gKGDOycJ//2n3fi0y8yyrPaZS4rK4thw0byj38MZeLEp5kwYQYrV67JU+aee37Ff/7z\nBP/5zxNce21/evc+LaLalr+X//0Bl1w3POpqlBqVYIrDHKCNpGMkVSEINj8a/SbpeKAeMDMmrZ6k\nquF8A+AMYEn+dWPFFYgkCRgHzDCzY82sc1ixpvnKHVILy8zuN7P3DmVdoCOQPzCMMbOOZnYisA+4\n+hC3He/+yt3JrY7km807WLtlF/uzspkwaw3nnZK3C7f1UbWZuSS4uM5cujk3f39WNvsOZANQpXIK\nKRX8TuHJbRvwzcYdrM3Yyf4D2Uyc8RXndW+ep0zrZnWYtXAjALMWbuK87gc/7J3Yqj4N6lbno/kb\nyrXeZW3hwhW0aNGEZs0aU6VKZS68sAdTpxbe2ps4cQb9+/coxxpG6+NPl7Etc2fU1Sg1pTl828wO\nALcAU4ClwOtmtjhsNFwcU/Qa4DUzi22OtQPmSvocmAYMjx1tV5B4L0E9gX1mNjKmot+Y2ZNhC2S8\npPeBqZJqSpoq6TNJiyTljrSQdG843vwj4LiY9NGSrgznO0v6IGx1TZHUJEyfLmmEpE/DbZwVRuph\nwNVhCyhPwAkD4xHAd+FyS0nvS1oY1rF5MelXSfpC0ueSZhS3v/KUVq86G7fuyV3etG03afWq5ymz\nbG0mfbsEnxX6dDmaWtUrU7dmFQCaHFmdiX/qy0ePX8SzE5axOXNv+VW+lKXVr8HGLbtylzd9u4u0\n+nkbwUu/+o4+p7cAoM9pzalZowp1a1VFgntuOJXh/5xTrnUuDxkZW2ncuEHuclpafTIythZYdv36\nzaxbl0H37ieVV/VcKUstwRQPM5tkZm3NrJWZPRSm3W9m42PKDDWzu/Ot94mZdTCzk8P//1ncvuIN\nRCcCnxWRfwpwpZmdDewFLjOzU4Bzgb8okNOKymlRnJp/I5IqA0+G2+oMPA88FFOkkpl1BW4HHgiH\nFd7PwRbQmLDc1ZIWEPRpHgm8HaY/CbxoZicBrwBPFJN+P9DXzE4GLi5ifwnpkVcX0PX4Roz/Yx+6\nHdeIjdt2k5UdfHDZuG0PF943hZ53TeTyM1tSv3bViGtbtoY/P4eu7Rsz/u8X0bVDYzZ9u4usbOPa\nC49n+tx1ee4X/RRNnDiDvn3PIDU13suUSzSl/YXW8nRIXWmSngbOJOj2ehpIN7NtOdnAw5J6ANkE\nQ/7SgLOAt8xsd7iNgr5texzQHkgPegNJBTbG5L8Z/j8PaFlEFceY2S1hl+LTwF3AcOA04PKwzMvA\nn8P5wtI/BkZLej1m30UKh0EOAmjQ7QZqtz2kW1/FyvhuD03qH2wBNT6yBhnf7clTZnPmXm564mMA\nalStRN9Tm7Jj9/4flVm+fjunHteQd+asK5O6lrWMrbtp0vCI3OXGDY4gI19g2bxtDzc/PA2AGtUq\ncf7pLdixax8dj2/IqSek8bMLjqdGtUpUqZzC7j0HePTFeeV6DGUhLa0+mzZ9m7uckbGVtLT6BZad\nNOlD7r9/cHlVzZWJBIwwcYq3RbSYoNUDgJndDPQCGoZJu2LK/ixM7xx+szYDiPdOuIDFYWujY9is\n6xOT/0P4fxZxBNGw3/Jt4JA6vs1sMHAfweiReZIK/ivOu84oM+tiZl3KKggBLFy9jZZptWja4Agq\np6bQv3tzps7PO6ilXs0quZ9+bryoHWNnfAVA43rVqVo5+ORbu0ZlurRtyOqNO8qsrmVt4fJvaXFU\nbZqm1aRypRQu7HEMU2evzVOmXu2quedi8FUd+Hf6CgDufOxDevzPWM755ViGPz+Xt95flRRBCKBD\nhzZ8/fUG1q7dxL59+5k4cQY9e3b9UblVq9by/fc76dTp+Ahq6UqLSvAv0cTbInqfoJVzo5k9E6YV\nNhKtDrDZzPZLOhdoEabPIGhdPBLu9yLg2Xzrfgk0lHSamc0Mu+ramtniIuq2A6hVRP6ZHBw2+AlB\n9+DLBAHzw6LSJbUys9nAbEn9CAJScfsrF1nZxoMvfcbo355NisTYGatZsf57br+8PYu+2sbU+Rvo\n1q4Rd111EgZ8umwLQ18KLrCtjqrNPQM6YgSR/x+TlrF83fYoD+ewZGUbD46cxQvDepOaIv6dvpIV\nazL59c868sWKrUz9dC3dOjRmyMDOmBlzvshg6DOzoq52matUKZX77x/MDTc8QFZWNldccR5t2rTg\n73//F+3bt6FXr25A0Bq64IKzUCL22ZShF5+8lbNOa0eDerVYOfsp/vjXsbw4ZnrU1TpkUsUddaS8\ngx2KKBgMGngc6AZsIWgFjQSqA13M7JawXAOCVkhNYC7QHehnZl9LuhcYCGwG1gCfmdljkkYDE8xs\nrKSOBPdo6hAErL+Z2XPhWPQhZjY33MdcM2sp6UiCkR2VgUfC+jxKcH8oheAbwdeb2ebwG8AvAA3C\nY/iFma0pIv1NoA3B9Xoqwb2perH7K+o+UavrxlTcHwgpRateuprW/UdHXY2EsHLC9cDyqKuRINpS\nvfmAqCuREPaseRUOs28tc9/kuK83dav0S6hPHXEHIldyHogCHogO8kAUywNRjtIIRNv3TYn7elOn\nSt+ECkT+ZAXnnEsCFblrzgORc84lhYRq5JSIByLnnEsCiTgaLl4eiJxzLgl4IHLOORep4EdVKyYP\nRM45lxS8ReSccy5C3jXnnHMuYj582znnXIS8ReSccy5SFflZgR6InHMuCSjun7xLPB6InHMuKXiL\nyDnnXIS8a84551zEPBA555yLkHz4tnPOuWh5i8g551yEUvz3iJxzzkXLA5FzzrkI+ZMVnHPORcwD\nkXPOuQhV5O8RycyirkMy85PrnIvXYUaS5SW43rRNqKjlgSjJSRpkZqOirkci8HNxkJ+Lg/xcRK/i\nDrNw8RoUdQUSiJ+Lg/xcHOTnImIeiJxzzkXKA5FzzrlIeSBKft73fZCfi4P8XBzk5yJiPljBOedc\npLxF5JxzLlIeiJxzzkXKA1EZkJQlaYGkLyS9LaluKW23paQvSmlboyV9FdZzgaTbSmO7hezrHEmn\nF5GfFVOPBZLuLmZ79xxCHd4Kt71S0vaYfRVar0Qg6VJJJun4QvJHS7qymG3EvtbLJD1QBnU84RDW\nS5P0/yStljRP0kxJlx1GPYZKGhLOD5N03iFup6OkC2KWr5e0JTx/iyWNlVTjUOtZ3P5+ijwQlY09\nZtbRzNoD24Cbo65QIe4K69nRzJ6IdyVJqSXczzlAURf8PTH16Ghmw4vZXoGBSIEC39NmdpmZdQRu\nAD6M2dcn+baRaI+9GgB8FP5/OO4Kj78jMFDSMYdds4MuBUoUiBQ8j2YcMMPMjjWzzsA1QNN85Q7p\n9TCz+83svUNZl+Ac5Q8MY8L3y4nAPuDqQ9x2vPv7SfFAVPZmAkcDSKopaaqkzyQtknRJmN5S0lJJ\nz4WfuN6VVD3M6yzpc0mfExPQJFWT9EK4nfmSzg3Tr5c0TlK6pK8l3SLpN2GZWZKOLKqykgaE2/xC\n0oiY9J2S/hLW47SwXh+En2SnSGoSlrtN0hJJCyW9JqklMBi4I/xEeVY8J01SHUlfSjouXH5V0q8k\nDQeqh9t6JTx3X0p6CfgCaCbpGUlzw3P5YBz7WidpuKT5wGWS2oTHNE/SDEltw3Jpkt4Mt/2ppO5h\nes/wNVoQvrZHxHOMcdSrJnAm8EuCi3ROsH0qPOb3gEYx5e+XNCd87UaFF/v8qoX/7wrX6RW+NxZJ\nel5S1WLSh8e8vo8paFFeDDwaHn+rOA+vJ7DPzEbmJJjZN2b2ZPgeHi/pfWBqYX83YX3ulbRc0kfA\ncTHpuS3FIt6r0yWNCF/L5ZLOklQFGAZcHR5PnoCjIDAeAXwXLreU9H54PqZKal5M+lXh6/N5+N4q\ncn8/GWbmUylPwM7w/1Tg38D54XIloHY43wBYSfB8qZbAAaBjmPc6cG04vxDoEc4/CnwRzt8JPB/O\nHw+sIbjIXB9utxbQENgODA7LPQ7cHs6PBr4CFoRTB+CocDsNw7q+D1waljfgv8L5ysAnQMNw+eqY\numwAqobzdcP/hwJDijhfWTH1WABcHab3Jgjk1wDv5D+/4XxLIBvoHpN2ZMz5nw6cFJN3DjAh3/7X\nAb+JWZ4GtArnzwDeDefH5Own3G/OazEZ6BbO1wRSS+l99DPgn+H8J0Bn4HIgPTy2o4BM4MrY4w7n\nXwYuKuC13gk8HKZXA9YCbcPll4Dbi0ivD3zJwdG2dWO2f2UJj+024PFC8q4PX5Oc17Gwv5vOwCKg\nBlA7TB8SWyeKfq9OB/4Szl8AvBez/6fy1WdLeP4ygA9zXmPgbWBgOP8/wLhi0hcBR+c7f3n291Oc\nvEVUNqpLWgBsAtIILhwQ/PE8LGkh8B5BSyktzPvKzBaE8/OAlgruLdU1sxlh+ssx+zgT+BeAmS0D\nvgHahnnTzGyHmW0hCERvh+mLCC6gOWK75hYBpwLTzWyLmR0AXgF6hGWzgDfC+eOA9kB6eJz3cbBL\nZSHwiqRrCYJrPPJ3zY0Jjys9rPPTBF1qhfnGzGbFLP+XpM+A+cCJxNdtNAYgPOfdgTfCY3ua4IIP\ncB4wMkwfB9RT0HL9GPi7pFsJLphZ8R12sQYAr4Xzr4XLPYBXzSzLzDYQfFjIca6k2ZIWEbQ4TozJ\ny+maawz0ClsyxxG875aHZV4Mt19Y+nZgL/BPSZcDu0vpOJH0dNhKmBMmpZvZtpxsCv67OQt4y8x2\nm9n3wPgCNl3UexXgzfD/eeT928hvTMz5WwTcFaafBvy/cP5lgr/LotI/BkZL+hXBhwmH/wxEWdlj\nZh0V3NCcQtCl9gTBJ9yGQGcz2y/paw52lfwQs34WUP0w9h+7reyY5WwO/TXfG3OBFbDYzE4roNyF\nBBeti4B7JXU4xP2h4H5PO4ILXj2CT8kF2RWzzjHAEOBUM/tO0mgOnuOi5GxDwLfhRedHVQK6mtm+\nfOl/kjSe4NhnSeplZivi2GehFHSh9gQ6SDKCi5YBbxVSvhrwf0AXM1sraSgFHLeZ7ZQ0neDCOKUk\ndTKzA5K6Ar0IWhu3hHU8FIuBK2K2fbOkBsDcMGlXTNmi/m6KU9R7FQ7+bWQRx9+GmZmkt4FbgeLu\nZRa0/mBJ3QjeK/MkdS7pNpKRt4jKkJntJuiCuDPsW64DbA7/mM4FWhSzfiaQKSnn09TPYrI/zFlW\ncA+jOUG3yeH4FDhbUgMFAxIGAB8UUO5LoKGk08L9V5Z0Yhg4mpnZNOB3BMdbE9hB0FVYUncAS4H/\nBl6QVDlM3x8zn19tgovYdklpQL+S7NDMvgM2Khy9JSlF0slh9nvkvU/XMfy/lZktNLNHgM+IuVdx\nGK4EXjazFmbW0syaEXSvbSW4n5Aa3us4Nyyfc2H+VsG9pQJH0oXvw27AKoLXsaWk1mH2zwle7wLT\nw+3WMbNJBK9Nznk5lNf3faCapBtj0gobiVbY380M4FJJ1SXVIvjwk1+B79Vi6lbc8ZxJcP4g6Pa7\nJpz/GcHfZaHp4XtltpndT9Dd1yyO/SU9D0RlzMzmE3RXDSDo6uoSdp1cByyLYxO/AJ4OuxVibz7/\nH5ASbmsMcL2Z/VDQBkpQ143A3QT3SD4H5pnZfwoot4/gQjdCweCFBQSj4lKBf4V1mg88EQbTtwkG\nARQ2WCFn8EHONFzBIIUbgDvN7EOCi859YflRwEJJrxRQt8/DfS8j6Br5+BBOxTXA4PDYFgP9w/Sb\ngTPCG9BLgF+F6UPCG9ALCe7BvHsI+8xvAD9u/bwBNAFWAEsI7t3MhNwPLc8RDNiYAszJt+6j4Xto\nIUHX0ptmtpfg/fXv8DXLBkYWlk5wsZwQHudHwG/Cbb8G3KVgcENcgxXMzAhG252tYGj5pwRdgL8r\noHiBfzdm9hnBe/9zgvt0+Y+5qPdqUaYBJ+QbPJAzmGAh0An4Y5h+K/CLMP3nwK+LSX9U4WAggmD1\neSH7+0nxR/w455yLlLeInHPORcoDkXPOuUh5IHLOORcpD0TOOeci5YHIOedcpDwQOeeci5QHIuec\nc5H6//pjPVTVxP61AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIdHunfsLkwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train), axis=1)\n",
        "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZWp4TAWLpOh",
        "colab_type": "text"
      },
      "source": [
        "# Second level learning model via XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlKZBo3zLnu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "36471790-c56d-4935-eb8e-3e43b36c17c0"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "gbm = xgb.XGBRegressor(\n",
        "    #learning_rate = 0.02,\n",
        " n_estimators= 2000,\n",
        " max_depth= 4,\n",
        " min_child_weight= 2,\n",
        " #gamma=1,\n",
        " gamma=0.9,                        \n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " nthread= -1,\n",
        " scale_pos_weight=1).fit(x_train, y_train)\n",
        "predictions = gbm.predict(x_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[01:03:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZfpK29aLqoI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "8cd8bfb6-41c6-4e52-c81f-15ce16cc2963"
      },
      "source": [
        "y_pred_y_test = pd.DataFrame(zip(predictions,y_test),\n",
        "                             columns=['y_pred','y_test'])\n",
        "y_pred_y_test.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_pred</th>\n",
              "      <th>y_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.477489</td>\n",
              "      <td>4.028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.199838</td>\n",
              "      <td>2.407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.072766</td>\n",
              "      <td>2.296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.125098</td>\n",
              "      <td>2.274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.201356</td>\n",
              "      <td>2.206</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y_pred  y_test\n",
              "0  3.477489   4.028\n",
              "1  2.199838   2.407\n",
              "2  2.072766   2.296\n",
              "3  2.125098   2.274\n",
              "4  2.201356   2.206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbdH6wLrLuze",
        "colab_type": "text"
      },
      "source": [
        "# R2 RMSE MAPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lHHgpkoLtGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(((y_pred - y_true) ** 2).mean())\n",
        "\n",
        "def mape(y_true, y_pred,dropinf=True):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    ape = np.abs((y_true - y_pred) / y_true)\n",
        "    if dropinf == True:\n",
        "      ape = ape[np.isfinite(ape)]\n",
        "    return np.mean(ape) * 100\n",
        "def evaluate(y_true,y_pred):\n",
        "  R2 = r2_score(y_true,y_pred)\n",
        "  RMSE = rmse(y_true,y_pred)\n",
        "  MAPE = mape(y_true,y_pred)\n",
        "  return pd.DataFrame({'R2':R2,\n",
        "                       'RMSE':RMSE,\n",
        "                       'MAPE':MAPE    \n",
        "  },index=[y_name])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfdR9VzLwsf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "85794e09-cb44-4c22-d148-624b036e711d"
      },
      "source": [
        "evaluate(predictions,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R2</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>MAPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C6N</th>\n",
              "      <td>0.768498</td>\n",
              "      <td>0.698902</td>\n",
              "      <td>8.815395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           R2      RMSE      MAPE\n",
              "C6N  0.768498  0.698902  8.815395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGcKtlj-LyCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}